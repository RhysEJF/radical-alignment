# Reality Anchoring

## Why Your Team Needs to Rehearse Reality Before Manufactured Conflicts Begin

You've been in this meeting before.

Two smart people, both genuinely trying to solve the same problem, somehow talking past each other completely. One person wants a systematic process with clear steps. The other wants to experiment and see what emerges. They're getting frustrated. Voices are rising. Someone accuses the other of being "too rigid." The other fires back about "lack of discipline."

It feels like a personality clash. Or a culture war. Or an ideological disagreement about the right way to work.

But it's none of those things.

What's actually happening is something more subtle and more solvable: they're operating in different Cynefin domains without realizing it.

And this confusion, this blurring of what kind of problem you're actually facing, is one of the most powerful weapons for manufacturing conflict and inserting crony beliefs into team dynamics.

## The Cynefin Framework

Developed by Dave Snowden, Cynefin distinguishes between four types of problems based on the relationship between cause and effect:

**Simple (now called "Clear"):** Cause and effect are obvious to everyone. Best practices apply. Sense-Categorize-Respond. "Follow the recipe."

**Complicated:** Cause and effect require analysis but are discoverable. Expert analysis applies. Sense-Analyze-Respond. "Call the engineer."

**Complex:** Cause and effect are only obvious in retrospect. The system is emergent. Probe-Sense-Respond. "Run experiments, see what works."

**Chaotic:** No relationship between cause and effect at system level. Act-Sense-Respond. "Stop the bleeding first, ask questions later."

Each domain requires fundamentally different approaches. The "right" strategy in one domain is the "wrong" strategy in another.

And here's where conflicts enter the picture.

When a team isn't anchored to reality, when they haven't agreed on which domain they're operating in, every conversation becomes vulnerable to domain confusion. And domain confusion is the perfect fog for crony beliefs to hide in.

## How Domain Confusion Creates Conflict

Imagine your team is facing a strategic decision. Let's say: "How should we approach this new market?"

Person A, coming from a Complicated domain assumption, wants to hire consultants, do deep analysis, create a comprehensive plan. This makes perfect sense if the market is Complicated, if there are knowable patterns that experts can discover and exploit.

Person B, coming from a Complex domain assumption, wants to run small experiments, stay nimble, iterate based on feedback. This makes perfect sense if the market is Complex, if patterns will only emerge through interaction.

They're both right. For different kinds of problems.

But if neither realizes they're operating from different domain assumptions, the conversation deteriorates fast.

Person A sees Person B as reckless, undisciplined, refusing to do the proper analysis. Person B sees Person A as rigid, afraid of uncertainty, wasting time on plans that will be obsolete.

The conflict feels real. It feels like they have fundamentally incompatible values. One wants order, the other wants freedom. (Sound familiar?)

But the actual disagreement isn't about values. It's about which domain the problem lives in.

## Exploiting The Fog

Now add crony beliefs to this confusion.

Let's say there's a third person in the room, someone with a vested interest in a particular outcome. Maybe they want the company to hire their friend's consulting firm. Or maybe they want to avoid accountability for a previous failed experiment.

This person can exploit the domain confusion to insert their agenda.

To Person A (Complicated-mindset): "Exactly! We need rigorous analysis. And I happen to know the perfect consultants..." (Crony belief: hire my friends.)

To Person B (Complex-mindset): "Right! We should experiment! And we shouldn't waste time on analysis that might prove our last approach was wrong..." (Crony belief: avoid accountability.)

The domain confusion creates the fog. The crony beliefs slip through it.

Neither Person A nor Person B realizes they're being manipulated, because they're too busy fighting about process to notice the agenda being inserted into the conversation.

This mergant conflict is not necessarily malicious. Sometimes it's accidental, but always exploiting the same vulnerability: teams that haven't anchored to reality can't distinguish genuine disagreements from fake ones.

This is where Reality Anchoring comes in.

## Reality Anchoring

Before you have the contentious meeting, before positions harden, before the fight begins, you rehearse reality.

Here's how it works:

### Step 1: Perspective Simulation

Take the problem and run it through AI perspective simulation. Configure proxies to roleplay your key stakeholders, but give each proxy a different domain assumption.

"Be the CFO who's treating this as a Complicated problem requiring expert analysis."

"Be the product manager who's treating this as a Complex problem requiring experimentation."

"Be the CEO who's treating this as a Simple problem with obvious best practices."

Let them argue. Let the proxies surface the implicit domain assumptions driving each perspective.

### Step 2: Map the Domain Confusion

Identify the moments where someone's proposed solution makes perfect sense in their assumed domain but sounds insane in another domain.

This is your map. This is where the manufactured conflict will emerge if you don't address it.

### Step 3: The Sensemaking Session

Before the real meeting, gather the actual team. Share what the simulation revealed.

"Here's what's interesting: when we simulated this discussion, we found that Finance is implicitly treating this as Complicated, Product is treating it as Complex, and Ops is treating it as Simple. We're not actually disagreeing about solutions, we're operating in different domains."

### Step 4: Anchor to Actual Reality

Now have the conversation you should have had first: "Which domain is this problem actually in?"

Look at the evidence together. Is cause-and-effect obvious (Simple)? Discoverable through analysis (Complicated)? Only visible in retrospect (Complex)? Not visible at all (Chaotic)?

This conversation is surprisingly easy once you name it explicitly. People quickly recognize their own domain assumptions and can evaluate them honestly.

### Step 5: Aligned Problem-Solving

Once everyone's anchored to the same domain, the "conflict" often dissolves entirely.

If it's actually Complicated, Person B stops resisting the expert analysis, they just want to make sure the experts are actually expert. If it's actually Complex, Person A stops pushing for the comprehensive plan, they just want to make sure the experiments have some structure.

They were never really in conflict. They just needed to agree on what kind of problem they were solving.

## Rehearsing Reality

You're not rehearsing your pitch. You're not rehearsing how to win the argument. You're rehearsing the actual terrain, figuring out what kind of problem you're facing before you start fighting about solutions.

And when you do this, something remarkable happens: crony beliefs lose their hiding place.

The consultant trying to sell their services can't exploit the Complicated-vs-Complex confusion if everyone's already agreed the problem is Complex.

The person avoiding accountability can't hide behind "we need to experiment more" if everyone's already agreed the problem is Complicated and needs expert analysis.

The fog clears. Reality becomes visible. Manufactured conflicts dissolve.

This doesn't eliminate all disagreement. Sometimes people genuinely disagree even when they're in the same domain. But it eliminates the fake disagreements, the ones that waste time, drain energy, and create openings for crony beliefs to slip through.

## A Practice, Not a Fix

Before any significant decision, ask: "Which domain are we in?"

Before any contentious meeting, run perspective simulation to map implicit domain assumptions.

Before launching any strategy, rehearse how it performs if the domain turns out to be different than you assumed.

Make domain clarity a team norm. Make it as automatic as asking "What's the goal?" or "What's the timeline?"

Because here's the deeper truth. Most team dysfunction isn't about bad people or broken culture. It's about operating in an artificially manufactured fog.

Clear the fog. Anchor to reality. Watch how many conflicts simply disappear.

This is the conversation space made practical. This is cognitive forking applied to collective sense-making. This is how teams build immunity against crony beliefs by refusing to let reality stay blurred.

When everyone can see the terrain clearly, everyone is has stronger immunity against croney beliefs.

The meeting you were dreading? It becomes the meeting where everyone's finally solving the same problem instead of fighting over different ones.

That's not magic. That's just what happens when you rehearse reality first.
